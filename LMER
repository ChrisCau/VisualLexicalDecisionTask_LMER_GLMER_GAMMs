################ Kodovi za ispit kod Veljka (LMER)

# Prvo da ucitam ove moje pakete koji mi trebaju (malo sam vise od onoga sto mi realno treba, ali neka)

require(rms)
require(lme4)
require(languageR)
require(multcomp)
require(lsmeans)
require(multcompView)
require(pbkrtest)
require(lmerTest)
require(party)
require(MASS)
require(ggplot2)
library(car)
require(mgcv)

# Ucitavam tabelu, koja mi je smestena u Documents

dat=read.table("viseznacnost_vld_finalno.txt", header=TRUE, quote="\"")

dim(dat)
#[1] 2023   18

# Da proverim jos jednom da li je ucitano sve dobro, proveravam 

colnames(dat)

# [1] "Ispitanik"            "TrialOrder"           "Grupa"               
# [4] "CorrectResponse"      "TrialNumber"          "Sufiks"              
# [7] "DuzinaSufiksa"        "Response"             "Tacnost"             
#[10] "RT"                   "NV"                   "Stimulus"            
#[13] "FrekLemKostic"        "PovFrekWac"           "FrekLemWac"          
#[16] "DuzinaReci"           "FrekvencijaSufiksa"   "ProduktivnostSufiksa"

# Sada polako treba da izbacim greske

# Sto se tice izbacivanje ispitanika, u psiholingvistici bas i ne postoji koncenzus koji procenat gresaka je znak za izbacivanje, ali vecina radi na 20% gresaka. Moje
# licno misljenje je da je to mozda malo labaviji kriterijum, ali kada je ovako mali uzorak (a u psiholingvistici svi su mali) nije student pametan koliko da izbaci, ja cu na 20% gresaka.

sort(tapply(dat$Tacnost, dat$Ispitanik, sum)/44)

#      s28       s31       s40       s22       s33       s29       s32       s39 
#0.7954545 0.7954545 0.7954545 0.8181818 0.8181818 0.8409091 0.8409091 0.8409091 
#      s41       s42        s5        s6       s23       s26       s37       s11 
#0.8409091 0.8409091 0.8409091 0.8409091 0.8636364 0.8636364 0.8636364 0.8863636 
#      s12       s16       s17       s18       s35       s36        s4       s46 
#0.8863636 0.8863636 0.8863636 0.8863636 0.8863636 0.8863636 0.8863636 0.8863636 
#       s7        s1       s19       s27       s44        s3       s30       s43 
#0.8863636 0.9090909 0.9090909 0.9090909 0.9090909 0.9318182 0.9318182 0.9318182 
#      s45        s8       s10       s13       s14       s15        s2       s21 
#0.9318182 0.9318182 0.9545455 0.9545455 0.9545455 0.9545455 0.9545455 0.9545455 
#      s24       s25       s34       s38       s20        s9 
#0.9545455 0.9545455 0.9545455 0.9545455 0.9772727 0.9772727

dat=dat[dat$Ispitanik!="s28",]
dat=dat[dat$Ispitanik!="s31",]
dat=dat[dat$Ispitanik!="s40",]

# Izbacena tri ispitanika.
----
# Ista prica je i sa stimulusima, uzecu kao kriterijum 25% posto je ogromna kolicina gresaka na malom uzorku, mislim da nema bas logike da uzmem nesto stroziji kriterijum.

sort(tapply(dat$Tacnost, dat$TrialNumber, sum)/23)

#       100        109         17        126         37         23         98 
#0.08695652 0.08695652 0.39130435 0.43478261 0.47826087 0.56521739 0.56521739 
#       115        129        130        117        119         27         96 
#0.60869565 0.60869565 0.60869565 0.65217391 0.65217391 0.69565217 0.69565217 
#       105        124         91        103        116         25         35 
#0.69565217 0.69565217 0.73913043 0.73913043 0.73913043 0.78260870 0.78260870 
#        38         94         99        106        113        122        128 
#0.78260870 0.78260870 0.78260870 0.78260870 0.78260870 0.78260870 0.78260870 
#        10         89         90         92         93         95         97 
#0.82608696 0.82608696 0.82608696 0.82608696 0.82608696 0.82608696 0.82608696 
#       101        102        104        107        108        110        111 
#0.82608696 0.82608696 0.82608696 0.82608696 0.82608696 0.82608696 0.82608696 
#       112        114        118        120        121        123        125 
#0.82608696 0.82608696 0.82608696 0.82608696 0.82608696 0.82608696 0.82608696 
#       127        131        132          6         19          2          7 
#0.82608696 0.82608696 0.82608696 0.86956522 0.91304348 0.95652174 0.95652174 
#        21          1          5          9         13         24         30 
#0.95652174 1.00000000 1.00000000 1.00000000 1.00000000 1.00000000 1.00000000 
#        31         34         40         44          3          4          8 
#1.00000000 1.00000000 1.00000000 1.00000000 1.04347826 1.04347826 1.04347826 
#        11         12         14         15         16         18         20 
#1.04347826 1.04347826 1.04347826 1.04347826 1.04347826 1.04347826 1.04347826 
#        22         26         28         29         32         33         36 
#1.04347826 1.04347826 1.04347826 1.04347826 1.04347826 1.04347826 1.04347826 
#        39         41         42         43 
#1.04347826 1.04347826 1.04347826 1.04347826

#Izbacivanje stimulusa sa vise od 25% gresaka

dat=dat[dat$TrialNumber!="100",]
dat=dat[dat$TrialNumber!="109",]
dat=dat[dat$TrialNumber!="17",]
dat=dat[dat$TrialNumber!="126",]
dat=dat[dat$TrialNumber!="37",]
dat=dat[dat$TrialNumber!="23",]
dat=dat[dat$TrialNumber!="98",]
dat=dat[dat$TrialNumber!="115",]
dat=dat[dat$TrialNumber!="129",]
dat=dat[dat$TrialNumber!="130",]
dat=dat[dat$TrialNumber!="117",]
dat=dat[dat$TrialNumber!="119",]
dat=dat[dat$TrialNumber!="27",]
dat=dat[dat$TrialNumber!="96",]
dat=dat[dat$TrialNumber!="105",]
dat=dat[dat$TrialNumber!="124",]
dat=dat[dat$TrialNumber!="91",]
dat=dat[dat$TrialNumber!="103",]
dat=dat[dat$TrialNumber!="116",]

dim(dat)
#[1] 1510   18

(2023-1510)/2023
#[1] 0.2535838

# Bas velika kolicina podataka koja je izbacena, ali to je problem eksperimentalnih istrazivanja jezika. :-(

-----------------------------------------

# Ispitujem po kojim kovarijablama se grupe razlikuju (imam dve grupe eksperimentalne, objasnjeno u radu). Uzmemo dva ispitanika (jednog iz jedne grupe, drugog iz druge),
# i napravimo kao neki maleni podskup, i na njemu radimo dalje, da ih ne selektujem sve (to sam negde na netu videla da se tako radi).

datx=dat[dat$Ispitanik=="s9" | dat$Ispitanik=="s38",]

dim(datx)
#69 18

----------------------
#Duzina reci (kovarijabla 1)
----------------------

aov.datx= aov(DuzinaReci~NV, data=datx)
summary (aov.datx)
print(model.tables(aov.datx, "means"),digits=3)
boxplot(DuzinaReci~NV, data=datx)

#            Df Sum Sq Mean Sq F value Pr(>F)  
#NV           1   8.07   8.067   3.913  0.052 .
#Residuals   67 138.14   2.062                
      
#    jedno  vise
#     7.77  7.08
#rep 30.00 39.00

# Duzina reci marginalno statisticki znacajna, to je ok, dakle skoro da se ne razlikuju.

-------------------------
#Frekvencija leme (srWac) (kovarijabla 2)
----------------------

aov.datx= aov(FrekLemWac~NV, data=datx)
summary (aov.datx)
print(model.tables(aov.datx, "means"),digits=3)
boxplot(FrekLemWac~NV, data=datx)

#            Df    Sum Sq   Mean Sq F value Pr(>F)  
#NV           1 7.527e+08 752655036   2.931 0.0915 .
#Residuals   67 1.721e+10 256825280 

#    jedno  vise
#     4812 11474
#      30    39

# Ovde nemamo razliku.

-------------------------
#Frekvencija povrsinska (srWac) (kovarijabla 3)
----------------------

aov.datx= aov(PovFrekWac~NV, data=datx)
summary (aov.datx)
print(model.tables(aov.datx, "means"),digits=3)
boxplot(PovFrekWac~NV, data=datx)

#            Df    Sum Sq  Mean Sq F value Pr(>F)
#NV           1 9.083e+07 90828467   2.694  0.105
#Residuals   67 2.259e+09 33709095  

#    jedno vise
#     1213 3527
#      30   39

# Takodje, ni ovde.

-------------------------
#Frekvencija sufiksa (kovarijabla 4)
-------------------------

aov.datx= aov(FrekvencijaSufiksa~NV, data=datx)
summary (aov.datx)
print(model.tables(aov.datx, "means"),digits=3)
boxplot(FrekvencijaSufiksa~NV, data=datx)

#            Df    Sum Sq  Mean Sq F value Pr(>F)
#NV           1 8.735e+05   873476   0.031  0.861
#Residuals   67 1.904e+09 28411434 

#    jedno vise
#     4280 4507
#      30   39

# Ni ovde nema razlike.

-------------------------
#Duzina sufiksa (kovarijabla 5)
-------------------------

aov.datx= aov(DuzinaSufiksa~NV, data=datx)
summary (aov.datx)
print(model.tables(aov.datx, "means"),digits=3)
boxplot(DuzinaSufiksa~NV, data=datx)

#            Df Sum Sq Mean Sq F value Pr(>F)
#NV           1   0.61  0.6105   0.903  0.345
#Residuals   67  45.30  0.6762  

#    jedno  vise
#     2.93  2.74
#    30.00 39.00

# Nema ni ovde, to je super.

-------------------------
#Produktivnost sufiksa (kovarijabla 6)
-------------------------

aov.datx= aov(ProduktivnostSufiksa~NV, data=datx)
summary (aov.datx)
print(model.tables(aov.datx, "means"),digits=3)
boxplot(ProduktivnostSufiksa~NV, data=datx)

#            Df   Sum Sq Mean Sq F value Pr(>F)  
#NV           1   768986  768986   3.587 0.0626 .
#Residuals   67 14365074  214404

#    jedno vise
#      409  196
#      30   39

# Nema ni ovde.
_____________________________________________
__________________________________________________________

# Nastavljam da sredjujem podatke.
# Izbacivanje netacnih odgovora (dodatno ciscenje, posto ne ociste mi se gore svi).

dat=dat[dat$Tacnost>0,]

dim(dat)
#[1] 1459   18

(2023-1459)/2023
#[1] 0.2787939

# Vizulena inspekcija podataka nakon svih ovih ciscenja, da vidimo kako izgledaju sada.

par(mfrow=c(2,2))
plot(sort(dat$RT))
plot(density(dat$RT))
qqnorm(dat$RT)
par(mfrow=c(1,1))

# Normalnost distribucije RT-ova sada testiram, iako bez izuzetaka ona nije ni priblizna normalnoj nikada.

shapiro.test(dat$RT)

#        Shapiro-Wilk normality test
#
#data:  dat$RT
#W = 0.81251, p-value < 2.2e-16

ks.test(jitter(dat$RT),"pnorm",mean(dat$RT),sd(dat$RT))

#        One-sample Kolmogorov-Smirnov test
#
#data:  jitter(dat$RT)
#D = 0.12999, p-value < 2.2e-16
#alternative hypothesis: two-sided

---

# U psiholingvistici skoro sve kovarijable (nase sve) se logaritmuju, a kada se RT-ovi mere u zadatku vizuelen leksicke odluke (izolovano prikazvanje) onda se i RT ispegla inverz transformacijom (Baayen&Milin, 2010)
# RT je dosta problematicna varijabla zato sto je distribucija naravno uvek zakrivljena i to bez izuzetaka na levo.

dat$dlem=log(dat$DuzinaReci)
dat$flemw=log(dat$FrekLemWac)
dat$fpov=log(dat$PovFrekWac)
dat$fsuf=log(dat$FrekvencijaSufiksa)
dat$dsuf=log(dat$DuzinaSufiksa)
dat$psuf=log(dat$ProduktivnostSufiksa)

# Inverzna transformacija RT

dat$RT=-1000/dat$RT

# Sada druga vizuelna inspekcija podataka, da vidim kako izgledaju.

par(mfrow=c(2,2))
plot(sort(dat$RT))
plot(density(dat$RT))
qqnorm(dat$RT)
par(mfrow=c(1,1))

# Priblizili smo je normalnoj, koliko je to bilo moguce.

----

# Normalizujem kontinuirane prediktore, da bismo mogli lepo da ih poredimo.

dat$trial.z = scale(dat$TrialOrder)
dat$len.z = scale(dat$dlem)
dat$flemw.z=scale(dat$flemw)
dat$fpov.z=scale(dat$fpov)
dat$fsuf.z = scale(dat$fsuf)
dat$dsuf.z = scale(dat$dsuf)
dat$psuf.z = scale(dat$psuf)

# Pobrinem se da je NV tretiran kao faktor, isto kao i slucajni efekti (Stimulusi i ispitanici)

as.factor(as.character(dat$NV))
levels(dat$NV)
table(dat$NV)

#jedno  vise 
#  638   821

as.factor(as.character(dat$Ispitanik))
levels(dat$Ispitanik)
table(dat$Ispitanik)

as.factor(as.character(dat$Stimulus))
levels(dat$Stimulus)
table(dat$Stimulus)
__________________________________________________________
________________________________________________________________

#Kontinuirane prediktore -- da vidim kako vizuelno to sve izgleda

-------------------------
#Trial Order
-------------------------

par(mfrow=c(2,2))
plot(sort(dat$TrialOrder))
plot(density(dat$TrialOrder))
qqnorm(dat$TrialOrder)
par(mfrow=c(1,1))

-------------------------
#Duzina Reci
-------------------------

par(mfrow=c(2,2))
plot(sort(dat$dlem))
plot(density(dat$dlem))
qqnorm(dat$dlem)
par(mfrow=c(1,1))

-------------------------
#Frekvencija Leme (srWac)
-------------------------

par(mfrow=c(2,2))
plot(sort(dat$flemw))
plot(density(dat$flemw))
qqnorm(dat$flemw)
par(mfrow=c(1,1))

-------------------------
#Frekvencija Reci (srWac)
-------------------------

par(mfrow=c(2,2))
plot(sort(dat$fpov))
plot(density(dat$fpov))
qqnorm(dat$fpov)
par(mfrow=c(1,1))

-------------------------
#Frekvencija Sufiksa 
-------------------------

par(mfrow=c(2,2))
plot(sort(dat$fsuf))
plot(density(dat$fsuf))
qqnorm(dat$fsuf)
par(mfrow=c(1,1))

-------------------------
#Duzina Sufiksa 
-------------------------

par(mfrow=c(2,2))
plot(sort(dat$dsuf))
plot(density(dat$dsuf))
qqnorm(dat$dsuf)
par(mfrow=c(1,1))

-------------------------
#Produktivnost Sufiksa 
-------------------------

par(mfrow=c(2,2))
plot(sort(dat$psuf))
plot(density(dat$psuf))
qqnorm(dat$psuf)
par(mfrow=c(1,1))

__________________________________________________________
____________________________________________________________

# Vizuelna inspekcija slucajnih efekata 

qqmath(~RT|Ispitanik,data=dat)

qqmath(~RT|TrialNumber,data=dat)

# Gotovo uvek potrebno prilagodjavanje nagiba (objasnjeno dole u kodu)

xylowess.fnc (RT~TrialOrder | Ispitanik, data=dat, ylab= "RT")

_________________________________________________________
________________________________________________________________

# Kolinearnost medju prediktorima (standardno OGROMNA u psiholingvistickim studijama, ali pokusacemo da izvuceno najbolje za ovaj model).

C=cov(dat[,c("flemw", "fpov", "fsuf", "dlem","dsuf", "psuf")], y = NULL, use = "everything", method = c("pearson", "kendall", "spearman"))
Cor=cov2cor(C)
Cor

#            flemw         fpov        fsuf         dlem         dsuf
#flemw  1.00000000  0.905425586  0.41265547 -0.013981066  0.038573858
#fpov   0.90542559  1.000000000  0.40709944 -0.031518323  0.004466912
#fsuf   0.41265547  0.407099445  1.00000000 -0.087493564 -0.249219862
#dlem  -0.01398107 -0.031518323 -0.08749356  1.000000000  0.606713809
#dsuf   0.03857386  0.004466912 -0.24921986  0.606713809  1.000000000
#psuf   0.29359685  0.324805426  0.91182233 -0.009582447 -0.192017732
#              psuf
#flemw  0.293596848
#fpov   0.324805426
#fsuf   0.911822333
#dlem  -0.009582447
#dsuf  -0.192017732
#psuf   1.000000000

# Kapa pre redukcije

collin.fnc(dat[,c("flemw", "fpov", "fsuf", "dlem", "dsuf", "psuf")])$cnumber

53.52064

# Ocekivano ogromne korelacija izmedju sledecih prediktora:

# povrsinska frekvencija reci i frekvencija leme, uzecemo frekevnciju leme kao prediktor (izbacicemo povrsinsku frekvenciju), cesce je koriscena u istrazivanjima, dokazan efekat u svim jezicima
# r = 0.90

# frekvencija sufiksa i produktivnost sufiksa, uzecemo produktivnost sufiksa, stabilnija je mera u prethodnim istrazivanjima
# r = 0.91

# duzina sufiksa i duzina reci, druga kovarijabla stabilniji efekat
# r = 0.60

# Dakle, da vidim visinu condition number (to se obicno koristi u psiholingvistici isto), preporuceno od Baayen 2008.
# Citala sam na netu da je prihvatljivo oko 12, dakle ovo je katastrofa. 

# Nakon redukcije

collin.fnc(dat[,c("flemw", "dlem", "psuf")])$cnumber

30.07801

# Malo je bolje bez duzine sufiksa kao kovariajble, ali generalno su jako bas korelirane sve te mere. 

############ PRVI PROBLEM, sta kada je koeficijent multikolinearnosti velik a ne mogu da izbacim kovarijate preostale, oni su mi jako vazni?!
________________________________________________________________________________
_________________________________________________________________________________________________________

################################################################# KRECEM POLAKO DA MODELUJEM


########## SLUCAJNI EFEKTI (ispitanika i stimulusa, testiramo da li je opravdano da ih uvrstimo u model?)

lmer0 <- lmer(RT ~ 1 + (1|Ispitanik) + (1|Stimulus),	data=dat)
ranefItem <- lmer(RT ~ 1 + (1|Stimulus),	data=dat)
ranefSubj <- lmer(RT ~ 1 + (1|Ispitanik), data=dat)

anova(ranefItem, lmer0)

#object: RT ~ 1 + (1 | Stimulus)
#..1: RT ~ 1 + (1 | Ispitanik) + (1 | Stimulus)
#       Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)    
#object  3 903.29 919.15 -448.65   897.29                             
#..1     4 425.02 446.16 -208.51   417.02 480.28      1  < 2.2e-16 ***

# Bolji je drugi model (AIC i BIC sto manji, LogLik sto veci), ja koliko sam citala po netu obicno se gleda AIC i LogLik da budu uskladjeni (AIC manji, LogLik veci)
# Da zakljucim, opravdano je da nam se u modelu nalazi slucajni efekat Ispitanika

anova(ranefSubj, lmer0)

#object: RT ~ 1 + (1 | Ispitanik)
#..1: RT ~ 1 + (1 | Ispitanik) + (1 | Stimulus)
#       Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)    
#object  3 613.26 629.11 -303.63   607.26                             
#..1     4 425.02 446.16 -208.51   417.02 190.24      1  < 2.2e-16 ***

# Opet je bolji drugi, dakle opravdano nam je da imamo u modelu i slucajni efekat Stimulusa
__________________________________________________________
________________________________________________________________

############# TRIAL ORDER 

# Ubacujem polako jedan po jedan prediktor, a proveravam i njihovu interakciju sa Ispitanicima (to je takodje cest slucaj, da je model bolji kada se uzme u obzir njihova interakcija).

lmer.dat <- lmer(RT ~ trial.z + (1|Ispitanik) + (1|Stimulus),	data=dat)
summary (lmer.dat)

#              Estimate Std. Error         df t value Pr(>|t|)    
#(Intercept) -1.433e+00  3.366e-02  6.360e+01 -42.563   <2e-16 ***
#trial.z      1.338e-03  6.836e-03  1.363e+03   0.196    0.845   

# Nije znacajan

-----------
# Sada testiram koji od dva modela mi je bolji

lmer.dat1 <- lmer(RT ~ trial.z  + (1|Ispitanik) + (0+trial.z|Ispitanik) +(1|Stimulus), data=dat)
summary (lmer.dat1)

lmer.dat.a=update(lmer.dat, REML=FALSE)
lmer.dat1.a=update(lmer.dat1, REML=FALSE)

anova(lmer.dat.a,lmer.dat1.a)

# Model je bolji kada nam je interakcija trial.z sa ispitanicima ukljucena (logicno).

------------------------

################ JEDAN PO JEDAN

lmer.dat2 <- lmer(RT ~ trial.z + NV + (1|Ispitanik) + (0+trial.z|Ispitanik) + (1|Stimulus), data=dat)
summary (lmer.dat2)

lmer.dat3 <- lmer(RT ~ trial.z + len.z + NV + (1|Ispitanik) + (0+trial.z|Ispitanik) + (1|Stimulus), data=dat)
summary (lmer.dat3)

lmer.dat4 <- lmer(RT ~ trial.z + len.z + flemw.z + NV + (1|Ispitanik) + (0+trial.z|Ispitanik) + (1|Stimulus), data=dat)
summary (lmer.dat4)

lmer.dat4 <- lmer(RT ~ trial.z + len.z + flemw.z + NV + psuf.z + (1|Ispitanik) + (0+trial.z|Ispitanik) + (1|Stimulus), data=dat)
summary (lmer.dat4)

lmer.dat5 <- lmer(RT ~ trial.z + flemw.z + + len.z + NV * psuf.z + (1|Ispitanik) + (0+trial.z|Ispitanik) + (1|Stimulus), data=dat)
summary (lmer.dat5)

lmer.dat4.a=update(lmer.dat4, REML=FALSE)
lmer.dat5.a=update(lmer.dat5, REML=FALSE)

anova(lmer.dat4.a,lmer.dat5.a)

# Najbolji model je lmer4, koji nema u obzir uzetu interakciju. Probala sam interakciju nezavisne varijable sa ostalim kovarijatima, nema nista.

---------------

############ TRENUTNI NAJBOLJI

lmer.dat4 <- lmer(RT ~ trial.z + len.z + flemw.z + NV + psuf.z + (1|Ispitanik) + (0+trial.z|Ispitanik) + (1|Stimulus), data=dat)
summary (lmer.dat4)

#Random effects:
# Groups      Name        Variance Std.Dev.
# Stimulus    (Intercept) 0.008210 0.09061 
# Ispitanik   trial.z     0.001027 0.03204 
# Ispitanik.1 (Intercept) 0.036390 0.19076 
# Residual                0.064592 0.25415 
#Number of obs: 1459, groups:  Stimulus, 69; Ispitanik, 43
#
#Fixed effects:
#              Estimate Std. Error         df t value Pr(>|t|)    
#(Intercept) -1.4350137  0.0355380 72.9000000 -40.380  < 2e-16 ***
#trial.z      0.0004021  0.0083831 43.8400000   0.048  0.96196    
#len.z        0.0416379  0.0130515 62.1200000   3.190  0.00223 ** 
#flemw.z     -0.0888833  0.0140523 61.9000000  -6.325 3.14e-08 ***
#NVvise       0.0033127  0.0279972 61.6800000   0.118  0.90620    
#psuf.z       0.0125082  0.0134979 61.4400000   0.927  0.35772   

-----------------------------------------------
---------------------------

#################### PODESAVANJE NAGIBA (tj. interakcija sa slucajnim efektima isptinaika)

lmer.dat8 <- lmer(RT ~ trial.z + len.z + flemw.z + NV + psuf.z + (1|Ispitanik) + (0+len.z|Ispitanik) + (1|Stimulus), data=dat)
summary (lmer.dat8)


lmer.dat4.a=update(lmer.dat4, REML=FALSE)
lmer.dat8.a=update(lmer.dat8, REML=FALSE)

anova(lmer.dat4.a,lmer.dat8.a)

#neujednaceni parametri, necu uzeti sa korekcijom

--------------------------

lmer.dat8 <- lmer(RT ~ trial.z + len.z + flemw.z + NV + psuf.z + (1|Ispitanik) + (0+flemw.z|Ispitanik) + (1|Stimulus), data=dat)
summary (lmer.dat8)

lmer.dat4.a=update(lmer.dat4, REML=FALSE)
lmer.dat8.a=update(lmer.dat8, REML=FALSE)

anova(lmer.dat4.a,lmer.dat8.a)

#isto neujednaceni

------------------------

lmer.dat8 <- lmer(RT ~ trial.z + len.z + flemw.z + NV + psuf.z + (1|Ispitanik) + (0+psuf.z|Ispitanik) + (1|Stimulus), data=dat)
summary (lmer.dat8)

lmer.dat4.a=update(lmer.dat4, REML=FALSE)
lmer.dat8.a=update(lmer.dat8, REML=FALSE)

anova(lmer.dat4.a,lmer.dat8.a)

#bolji bez

----------------------------
---------------------------------------------
---------------------------------------------------------

########################## TRENUTNO NAJBOLJI #######

lmer.dat6 <- lmer(RT ~ trial.z + len.z + flemw.z + NV + psuf.z + (1|Ispitanik) + (0+trial.z|Ispitanik) + (1|Stimulus), data=dat)
summary (lmer.dat6)

----------------------------

#Random effects:
# Groups      Name        Variance Std.Dev.
# Stimulus    (Intercept) 0.008210 0.09061 
# Ispitanik   trial.z     0.001027 0.03204 
# Ispitanik.1 (Intercept) 0.036390 0.19076 
# Residual                0.064592 0.25415 
#Number of obs: 1459, groups:  Stimulus, 69; Ispitanik, 43
#
#Fixed effects:
#              Estimate Std. Error         df t value Pr(>|t|)    
#(Intercept) -1.4350137  0.0355380 72.9000000 -40.380  < 2e-16 ***
#trial.z      0.0004021  0.0083831 43.8400000   0.048  0.96196    
#len.z        0.0416379  0.0130515 62.1200000   3.190  0.00223 ** 
#flemw.z     -0.0888833  0.0140523 61.9000000  -6.325 3.14e-08 ***
#NVvise       0.0033127  0.0279972 61.6800000   0.118  0.90620    
#psuf.z       0.0125082  0.0134979 61.4400000   0.927  0.35772  

---------------------
---------------------------

ranef(lmer.dat6)$Ispitanik (pregled za svakog ispitanika i ove varijable za koju je nagib podesen)

#          trial.z (Intercept)
#s1  -0.0261511185 -0.13510057
#s10  0.0441601983  0.07510954
#s11 -0.0241899635  0.24519169
#s12 -0.0022031274 -0.01350531
#s13  0.0152457106  0.03241970
#s14  0.0107564716 -0.14588260
#s15 -0.0037011996 -0.10852194
#s16  0.0158982601  0.38772444
#s17 -0.0064846701  0.23753746
#s18 -0.0424110529 -0.04113167
#s19  0.0073646755 -0.05938192
#s2   0.0196141217 -0.15593493
#s20  0.0009317657 -0.10057086
#s21 -0.0055724543  0.25183077
#s22  0.0102212631  0.05197159
#s23  0.0229507163  0.20914503
#s24  0.0113164374 -0.06160177
#s25 -0.0086537775  0.28282333
#s26  0.0069408211 -0.04112307
#s27 -0.0208929570  0.01473557
#s29  0.0007415683 -0.18400722
#s3   0.0338093209 -0.14564334
#s30  0.0344618994 -0.14107646
#s32 -0.0224186462 -0.20693928
#s33  0.0098615207 -0.13497529
#s34 -0.0147641925  0.11145452
#s35  0.0040580954  0.02210948
#s36  0.0055279374  0.18996579
#s37 -0.0087063241  0.15626129
#s38  0.0048539663 -0.08511310
#s39  0.0084939522  0.24204961
#s4   0.0154195643 -0.05798009
#s41  0.0164967839 -0.04936030
#s42  0.0039758007  0.26254832
#s43 -0.0173482131 -0.10910591
#s44 -0.0076562509 -0.21867519
#s45  0.0164707779 -0.26703325
#s46 -0.0060290241  0.47153084
#s5  -0.0232340464 -0.19860886
#s6  -0.0264380332 -0.27288522
#s7  -0.0097706844  0.05176050
#s8  -0.0328820748 -0.16353184
#s9  -0.0100638183 -0.19847949

-------------
-----------------------

#################### KRITIKA MODELA (Baayen & Milin, 2010) + Perform model-based (Semi-)parametric bootstrap for mixed models (tj. maleni Bootstrap za ovaj lmer)

confint(lmer.dat6)

#                   2.5 %      97.5 %
#.sig01       0.067343817  0.11011008
#.sig02       0.003920078  0.05106989
#.sig03       0.152658560  0.23927179
#.sigma       0.244721987  0.26421692
#(Intercept) -1.504399382 -1.36576934
#trial.z     -0.016254779  0.01694805
#len.z        0.016510465  0.06675883
#flemw.z     -0.115907401 -0.06180268
#NVvise      -0.050538791  0.05725383
#psuf.z      -0.013503760  0.03847163


par(mfrow=c(2,3))
plot(fitted(lmer.dat6),residuals(lmer.dat6))
plot(fitted(lmer.dat6),scale(residuals(lmer.dat6)))
qqnorm(residuals(lmer.dat6), main=" ")
qqline(residuals(lmer.dat6))
plot(fitted(lmer.dat6),residuals(lmer.dat6))
plot(fitted(lmer.dat6),scale(residuals(lmer.dat6)))
qqnorm(residuals(lmer.dat6), main=" ")
qqline(residuals(lmer.dat6))
par(mfrow=c(1,1))

b1=bootMer(lmer.dat6, FUN = function(x) as.numeric(logLik(x)), nsim = 100)

head(as.data.frame(b1))

#         V1
#1 -203.5195
#2 -207.0842
#3 -175.8897
#4 -247.4717
#5 -220.8579
#6 -157.5027

plot(b1$t)

-------------
------------------------

# Za kraj, samo cu da obrnem nivoe NV (dakle da mi na intercept budu mapirani viseznacne sufikse, da vidim da li se menja ista)
 
dat$NV <- relevel(dat$NV, ref = "vise")

lmer.dat6 <- lmer(RT ~ trial.z + len.z + flemw.z + NV + psuf.z + (1|Ispitanik) + (0+trial.z|Ispitanik) + (1|Stimulus), data=dat)
summary (lmer.dat6)

lmer.dat6.a <- lmer(RT ~ trial.z + len.z + flemw.z + NV + psuf.z + (1|Ispitanik) + (0+trial.z|Ispitanik) + (1|Stimulus), data=dat, subset=abs(scale(resid(lmer.dat6)))<2.5)
summary (lmer.dat6.a)

#Random effects:
# Groups      Name        Variance Std.Dev.
# Stimulus    (Intercept) 0.008874 0.09420 
# Ispitanik   trial.z     0.001127 0.03357 
# Ispitanik.1 (Intercept) 0.036778 0.19178 
# Residual                0.057698 0.24020 
#Number of obs: 1441, groups:  Stimulus, 69; Ispitanik, 43
#
#Fixed effects:
#             Estimate Std. Error        df t value Pr(>|t|)    
#(Intercept) -1.435255   0.034303 66.180000 -41.840  < 2e-16 ***
#trial.z     -0.004094   0.008295 44.530000  -0.494  0.62401    
#len.z        0.043319   0.013262 62.120000   3.266  0.00178 ** 
#flemw.z     -0.088003   0.014271 61.770000  -6.166 5.88e-08 ***
#NVjedno     -0.009859   0.028461 61.780000  -0.346  0.73023    
#psuf.z       0.007648   0.013733 61.750000   0.557  0.57960 
